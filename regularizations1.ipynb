{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd60ed1",
   "metadata": {},
   "source": [
    "### 손글씨 데이터셋 (MNIST)을 활용한 분류모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027e0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 불러오기\n",
    "import numpy as np                     # 수치 연산\n",
    "import pandas as pd                    # DataFrame 처리\n",
    "import matplotlib.pyplot as plt        # 시각화 (그래프)\n",
    "import seaborn as sns                  # 시각화 (차트)\n",
    "\n",
    "# torch 계열 라이브러리\n",
    "import torch                           # Pytorch 핵심 패키지\n",
    "import torch.nn as nn                  # 신경망 레이어/모듈\n",
    "import torch.nn.functional as F        # 활성화/손실 함수 등 함수 API\n",
    "import torch.optim as optim            # 최적화함수 Optimizer\n",
    "\n",
    "# 데이터셋 및 전처리\n",
    "from torchvision import datasets, transforms  # 기본 데이터셋 로딩, 데이터셋 전처리\n",
    "\n",
    "# 검증\n",
    "from sklearn.metrics import confusion_matrix  # 혼동행렬 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782c63e",
   "metadata": {},
   "source": [
    "- MNIST (손글씨 숫자 이미지) 데이터셋 다운로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61344786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습용 (MNIST Train) 데이터셋\n",
    "train = datasets.MNIST(                 # MNIST 학습 데이터셋 객체 생성\n",
    "    './data',                           # 데이터 저장 경로\n",
    "    train=True,                         # 학습(train) 데이터셋 사용\n",
    "    download=True,                      # 없으면 인터넷에서 다운로드\n",
    "    transform = transforms.Compose([    # 전처리를 순서대로 적용 (전처리 파이프라인)\n",
    "        transforms.ToTensor()           # PIL/ndarray -> torch.Tensor(0~1 스케일)\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 테스트용 (MNIST Test) 데이터셋\n",
    "test = datasets.MNIST(\n",
    "    './data',\n",
    "    train=False,                        # 테스트(Test) 데이터셋 사용\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51da24df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = train[0]    # 0번째 샘플에서 (이미지 텐서, 정답 라벨) 추출\n",
    "img.shape                # 이미지 텐서 모양 확인 (1, 28, 28) : (채널, 높이, 너비)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a256a3",
   "metadata": {},
   "source": [
    "- Pytorch(MNIST) / Conv : channel-first (C, H, W)  \n",
    "- Numpy / OpenCV / matplotlib / Tensorflow : channel-last (H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d58a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습데이터 랜덤으로 10장 확인\n",
    "idxs = np.random.choice(len(train), size=10, replace=False)  # 전체 중 랜덤 10개 인덱스\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i, idx in enumerate(idxs):\n",
    "    img, label = train[idx]      # 랜덤 샘플 (이미지 텐서, 라벨)  \n",
    "    plt.subplot(2, 5, i + 1)     # 2행 5열\n",
    "    plt.imshow(img.squeeze(0), cmap='gray')   # (1, 28, 28) -> (28, 28)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")              # 축 제거\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544dd1c5",
   "metadata": {},
   "source": [
    "plt.imshow() 에서 받는 형태  \n",
    "흑백 : (H, W)  \n",
    "컬러 : (H, W, C)  \n",
    "컬러 이미지의 경우 Pytorch 데이터셋이 (C, H, W) 형태라면 imshow()로 출력하기 위해서는 (H, W, C) 형태로 맞춰줘야 한다.\n",
    "\n",
    "``` python\n",
    "img_hwc = img.permute(1, 2, 0)    # (C, H, W) -> (H, W, C)\n",
    "plt.imshow(img_hwc)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fdc9e",
   "metadata": {},
   "source": [
    "- MNIST 입력 / 정답 텐서 전처리 및 차원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050340eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 784]) torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# 이미지 정규화 및 실수형 변환\n",
    "x = train.data.float() / 255.  # RGB값 (0~255) -> 0~1로 스케일링\n",
    "y = train.targets              # 각 이미지 정답 라벨 (텐서)\n",
    "\n",
    "print(x.size())\n",
    "\n",
    "# 입력 텐서 형태 변환\n",
    "x = x.view(x.size(0), -1)      # (N, 28, 28) -> (N, 784)로 펼쳐짐(flatten)\n",
    "\n",
    "print(x.shape, y.shape)        # x : (N, 784), y : (샘플수, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0644b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size : 784, output_size = 10\n"
     ]
    }
   ],
   "source": [
    "# 입력/출력 차원 정의\n",
    "input_size = x.size(-1)          # 입력 특성 수 (784)\n",
    "output_size = int(max(y)) + 1    # 라벨 최대값 + 1 = 클래스 갯수 10\n",
    "\n",
    "print(f\"input size : {input_size}, output_size = {output_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21600e23",
   "metadata": {},
   "source": [
    "- 학습 / 검증 / 테스트 데이터셋 분리 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34439254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_cnt = 48000, valid_cnt = 12000, test_cnt = 10000\n"
     ]
    }
   ],
   "source": [
    "# 학습/검증 데이터셋 비율 설정 및 개수 계산\n",
    "ratios = [.8, .2]                              # Train / Valid 비율 (80%:20%)\n",
    "\n",
    "train_cnt = int(x.size(0) * ratios[0])         # 전체 샘플 중 학습 샘플 수\n",
    "valid_cnt = int(x.size(0) * ratios[1])         # 전체 샘플 중 검증 샘플 수\n",
    "test_cnt = len(test.data)                      # 테스트 샘플 수\n",
    "cnts = [train_cnt, valid_cnt]                  # split에 사용할 [train, valid] 크기\n",
    "\n",
    "print(f\"Train_cnt = {train_cnt}, valid_cnt = {valid_cnt}, test_cnt = {test_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc20ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 데이터셋 무작위 셔플 및 분할\n",
    "indices = torch.randperm(x.size(0))  # 0 ~ N-1 인덱스 랜덤 순서로 생성\n",
    "\n",
    "x = torch.index_select(x, dim=0, index=indices)    # 랜덤 index 순서로 x를 재정렬\n",
    "y = torch.index_select(y, dim=0, index=indices)    # 랜덤 index 순서로 y를 재정렬\n",
    "\n",
    "x = list(x.split(cnts, dim=0))    # x를 train/valid 크기로 나눠 리스트로 반환\n",
    "y = list(y.split(cnts, dim=0))    # y를 train/valid 크기로 나눠 리스트로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d2fd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48000, 784]) torch.Size([48000])\n",
      "torch.Size([12000, 784]) torch.Size([12000])\n",
      "torch.Size([10000, 784]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# 테스트데이터 정규화 및 추가\n",
    "x += [(test.data.float() / 255.).view(test_cnt, -1)]  # 테스트 x를 0~1로 정규화 후 (N, 784)로 펼쳐 추가\n",
    "y += [test.targets]                                   # y도 list로 추가\n",
    "\n",
    "# 최종 데이터셋 크기 출력\n",
    "for x_i, y_i in zip(x, y):             # (train, valid, test) 순서로 순회\n",
    "    print(x_i.size(), y_i.size())      # 각 데이터셋의 입력/라벨 텐서 크기 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dcc6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    # 입력 -> 선형변환 -> 활성화 -> (BatchNorm or Dropout)으로 구성된 블록을 초기화하는 생성자\n",
    "    def __init__(self, input_size, output_size, use_batch_norm=True, dropout_p=.4):\n",
    "        self.input_size = input_size              # 입력 차원 저장\n",
    "        self.output_size = output_size            # 출력 차원 저장\n",
    "        self.use_batch_norm = use_batch_norm      # BN 사용 여부 저장\n",
    "        self.dropout_p = dropout_p                # Dropout 비율 저장\n",
    "\n",
    "        super().__init__()                        # nn.Module 초기화\n",
    "\n",
    "        # BN을 사용할지, Dropout을 사용할지 선택해서 정규화 모듈을 반환하는 함수\n",
    "        def get_regularizer(use_batch_norm, size):\n",
    "            return nn.BatchNorm1d(size) if use_batch_norm else nn.Dropout(dropout_p)  # BN 또는 Dropout 선택\n",
    "        \n",
    "        self.block = nn.Sequential(                        # 레이어들을 순서대로 묶어 하나의 블록으로 구성\n",
    "            nn.Linear(input_size, output_size),            # input_size -> output_size 선형 변환\n",
    "            nn.LeakyReLU(),                                # 음수 영역도 기울기 유지하는 활성화 함수\n",
    "            get_regularizer(use_batch_norm, output_size)   # BatchNorm1d(output_size) 또는 Dropout(dropout_p)\n",
    "        )\n",
    "\n",
    "    # 입력 x를 block을 통과시켜 출력 y를 만드는 순전파\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)    # 텐서의 모양 약속/설명\n",
    "        y = self.block(x)                   # Linear -> LeakyReLU -> (BN/Dropout) 적용 \n",
    "        # |y| = (batch_size, output_size)   # 텐서의 모양 약속/설명\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e89b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "\n",
    "    # 여러 개의 Block을 쌓아 분류용 MLP (출력층 LogSoftmax 활성화함수)을 구성한다.\n",
    "    def __init__(self, input_size, output_size, use_batch_norm=True, dropout_p=.4):\n",
    "        super().__init__()               # nn.Module 초기화\n",
    "\n",
    "        self.layers = nn.Sequential(     # 레이어들을 순서대로 묶어 모델 구성\n",
    "            Block(input_size, 500, use_batch_norm, dropout_p),   # 입력 차원 -> 500 차원 블록\n",
    "            Block(500, 400, use_batch_norm, dropout_p),          # 500 -> 400 차원(노드) 블록\n",
    "            Block(400, 300, use_batch_norm, dropout_p),          # 400 -> 300 차원(노드) 블록\n",
    "            Block(300, 200, use_batch_norm, dropout_p),          # 300 -> 200 차원(노드) 블록\n",
    "            Block(200, 100, use_batch_norm, dropout_p),          # 200 -> 100 차원(노드) 블록\n",
    "            nn.Linear(100, output_size),                         # 마지막 은닉(100) -> 출력(output_size) 선형 변환\n",
    "            nn.LogSoftmax(dim=1)                                 # 클래스 차원 (dim-1) 기준 log-확률로 변환\n",
    "        )\n",
    "\n",
    "    # 입력 x를 순차 레이어(self.layers)에 통과시켜 최종 출력 y를 만드는 순전파\n",
    "    def forward(self, x):\n",
    "        # |x| = (batch_size, input_size)    # 텐서의 모양 약속/설명\n",
    "        y = self.layers(x)                  # Block들 -> Linear -> LogSoftmax 순서로 통과\n",
    "        # |y| = (batch_size, output_size)   # 텐서의 모양 약속/설명\n",
    "\n",
    "        return y  # 각 클래스별 log-확률로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12094aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (layers): Sequential(\n",
       "    (0): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=500, out_features=400, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=400, out_features=300, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=200, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (6): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(\n",
    "    input_size,              # 입력 벡터 차원 (784)\n",
    "    output_size,             # 출력 벡터 차원 (10)\n",
    "    use_batch_norm=True      # 각 Block에서 BatchNorm 사용 (Dropout은 사용하지 않음)\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e57456f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 : NLLLoss (음의 로그 우도 손실) = LogSoftmax 출력(log-확률)과 함께 사용한다.\n",
    "crit = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87d2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(    # lr 기본값 0.001 사용한 Adam Optimizer\n",
    "    model.parameters()     # 학습 대상 파라미터 (가중치/편향) 전달\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ede298b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 GPU 사용가능시 \"cuda\"로, 불가시 \"cpu\" (삼항연산자)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "169eae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 데이터셋을 선택된 장치(GPU or CPU)로 이동시키기\n",
    "model = model.to(device)  # 모델 파라미터를 device(cuda/cpu)로 이동\n",
    "\n",
    "x = [x_i.to(device) for x_i in x]  # (train/valid/test) 입력 텐서들을 device로 이동\n",
    "y = [y_i.to(device) for y_i in y]  # (train/valid/test) 라벨 텐서들을 device로 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec024d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 하이퍼파라미터 설정\n",
    "n_epochs = 1000         # 학습 반복\n",
    "batch_size = 256        # 미니배치 크기 (한번에 학습할 샘플 수)\n",
    "print_interval = 10     # 로그 출력 주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19f3171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping 설정\n",
    "from copy import deepcopy    # 객체(모델 파라미터) 복사 유틸\n",
    "\n",
    "lowest_loss = np.inf         # 검증 손실 최소값\n",
    "best_model = None            # 최고 성능 모델\n",
    "\n",
    "early_stop = 50              # 개선이 없을 시 중단할 patience (기다림 횟수)\n",
    "lowest_epoch = np.inf        # 최솟값 갱신된 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abca29a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f12653dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g7/6_f4vlmd2tnf4ghbk1n9tv_40000gn/T/ipykernel_46687/2704277428.py:30: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:837.)\n",
      "  train_loss += float(loss)             # 텐서 -> 파이썬 float로 누적 (그래프 참조 방지)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train_loss = 1.5399e-02, valid_loss = 9.7274e-02, lowest_loss = 7.2845e-02\n",
      "Epoch 20, train_loss = 9.0590e-03, valid_loss = 7.8127e-02, lowest_loss = 7.2845e-02\n",
      "Epoch 30, train_loss = 9.8080e-03, valid_loss = 1.1204e-01, lowest_loss = 7.2845e-02\n",
      " 50 에포크만큼 진행되었으나 더이상 향상되지 않음\n",
      "가장 손실이 낮은 에포크 : 9, 이 때 최소 손실값은 : 0.07284543851509373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 루프 + 검증 + Early Stopping\n",
    "\n",
    "# 손실 기록 리스트 초기화\n",
    "train_history, valid_history = [], []    # epoch별 train/valid loss 저장 리스트\n",
    "\n",
    "# 에폭 반복\n",
    "for i in range(n_epochs):\n",
    "    model.train()        # 학습모드 (Dropout/BN 등 활성화)\n",
    "\n",
    "    # 학습 데이터 셔플 및 미니배치 분할\n",
    "    indices = torch.randperm(x[0].size(0)).to(device)      # 학습 데이터 인덱스 랜덤 셔플\n",
    "    x_ = torch.index_select(x[0], dim=0, index=indices)    # 셔플된 순서로 train x 재정렬\n",
    "    y_ = torch.index_select(y[0], dim=0, index=indices)    # 셔플된 순서로 train y 재정렬\n",
    "\n",
    "    x_ = x_.split(batch_size, dim=0)   # 미니배치 단위로 분할 (튜플 반환) \n",
    "    y_ = y_.split(batch_size, dim=0)   # 미니배치 단위로 분할 (튜플 반환) \n",
    "\n",
    "    train_loss, valid_loss = 0, 0      # epoch 누적 손실 평균\n",
    "    y_hat = []                         # 검증 예측값 저장\n",
    "\n",
    "    # 미니배치 단위로 학습\n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i = model(x_i)                  # 순전파 : logits 계산\n",
    "        loss = crit(y_hat_i, y_i.squeeze())   # 손실 계산 (shape은 (N, )형태로 변환)\n",
    "\n",
    "        optimizer.zero_grad()                 # 이전 배치 기울기 초기화\n",
    "        loss.backward()                       # 역전파 : 기울기 계산\n",
    "\n",
    "        optimizer.step()                      # 파라미터 업데이트\n",
    "        train_loss += float(loss)             # 텐서 -> 파이썬 float로 누적 (그래프 참조 방지)\n",
    "    \n",
    "    # 손실 평균\n",
    "    train_loss = train_loss / len(x_)         # 미니배치 평균 train_loss 계산\n",
    "\n",
    "    # 검증\n",
    "    model.eval()                              # 평가 모드(Dropout 비활성화, BN 고정)\n",
    "    with torch.no_grad():                     # 검증은 기울기 계산 생략\n",
    "        x_ = x[1].split(batch_size, dim=0)    # valid x를 미니배치 단위로 분할\n",
    "        y_ = y[1].split(batch_size, dim=0)    # valid y를 미니배치 단위로 분할\n",
    "\n",
    "        valid_loss = 0                        # valid loss 누적값 초기화\n",
    "\n",
    "        # 검증 손실 계산\n",
    "        for x_i, y_i in zip(x_, y_):\n",
    "            y_hat_i = model(x_i)                  # 순전파 : 예측 계산\n",
    "            loss = crit(y_hat_i, y_i.squeeze())   # 손실 계산\n",
    "\n",
    "            valid_loss += float(loss)             # 텐서 -> 숫자로 누적\n",
    "\n",
    "            y_hat += [y_hat_i]                    # 예측값 저장\n",
    "    \n",
    "    # 손실 평균 및 기록\n",
    "    valid_loss = valid_loss / len(x_)    # 미니배치 평균으로 valid_loss 계산\n",
    "\n",
    "    train_history += [train_loss]    # train_loss 저장\n",
    "    valid_history += [valid_loss]    # valid_loss 저장\n",
    "\n",
    "    # 일정 간격마다 로그 출력\n",
    "    if (i + 1) % print_interval == 0:\n",
    "        print(f\"Epoch {i + 1}, train_loss = {train_loss:.4e}, valid_loss = {valid_loss:.4e}, lowest_loss = {lowest_loss:.4e}\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if valid_loss <= lowest_loss:        # valid_loss가 개선이 되면\n",
    "        lowest_loss = valid_loss         # 최저 손실 갱신\n",
    "        lowest_epoch = i                 # 현재 epoch 기록\n",
    "\n",
    "        best_model = deepcopy(model.state_dict())    # 현재 모델 가중치 스냅샷 저장\n",
    "    else:\n",
    "        if early_stop > 0 and lowest_epoch + early_stop < i + i:      # patience 초과 여부 확인\n",
    "            print(f\" {early_stop} 에포크만큼 진행되었으나 더이상 향상되지 않음\")\n",
    "            break\n",
    "\n",
    "print(f\"가장 손실이 낮은 에포크 : {lowest_epoch + 1}, 이 때 최소 손실값은 : {lowest_loss}\")\n",
    "\n",
    "# 최적의 모델 복원\n",
    "model.load_state_dict(best_model)    # 저장해둔 best weight로 모델 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd3754d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 손실 이력 시각화\n",
    "plot_from = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
