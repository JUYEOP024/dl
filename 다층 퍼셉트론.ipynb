{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ae7a4a",
   "metadata": {},
   "source": [
    "## 다층 퍼셉트론으로 XOR문제를 해결 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a8122f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                        # 텐서 및 기본 연산 지원\n",
    "import torch.nn as nn               # 신경망 모델 구성 도(nn.Linear, nn.Sequential 등)\n",
    "import torch.optim as optim         # 최적화 알고리즘 (SGD, Adam 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17882b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [[0], [1], [1], [0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc4d01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(X)            # 입력 데이터 Tensor \n",
    "y = torch.FloatTensor(y)            # 정답 레이블 데이터 tensor\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8acf548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의( 다층 퍼셉트론)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 4),        # 입력 2개 -> 은닉층 4개\n",
    "    nn.Tanh(),              # 은닉층 활성화 함수 (tanh는 신경망에 비선형성을 추가해준다) \n",
    "    nn.Linear(4, 1),        # 은닉층 4개 -> 출력 1개\n",
    "    nn.Sigmoid()            # 출력층 활성화 함수(출력값을 0~1 확률로 변환)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65312cc9",
   "metadata": {},
   "source": [
    "손실함수 BCELoss() : 이진 분류용 손실함수 Sigmoid 출력과 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856220f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수와 옵티마이저 설정\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(      # 확률적 경사 하강법 SGD\n",
    "    model.parameters(),     # 학습할 가중치와 편향\n",
    "    lr = 0.1                # 학습률\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54705e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0: loss=0.6938\n",
      "Epoch1000: loss=0.1124\n",
      "Epoch2000: loss=0.0203\n",
      "Epoch3000: loss=0.0105\n",
      "Epoch4000: loss=0.0070\n",
      "Epoch5000: loss=0.0052\n",
      "Epoch6000: loss=0.0042\n",
      "Epoch7000: loss=0.0034\n",
      "Epoch8000: loss=0.0029\n",
      "Epoch9000: loss=0.0026\n",
      "최종 예측: tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# 학습 루트\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()           # 이전 step 에서 계산된 gradient 를 0으로 초기화\n",
    "    output = model(X)               # 순전파(forward pass) : 입력 X값을 모델에 통과시켜 예측값 계산\n",
    "    loss = criterion(output, y)     # 예측값(output)과 실제값(y)의 차이 측정 =손실 계산\n",
    "    loss.backward()                 # 역전파 (backpropagation) : 손실을 기준으로 각 마라미터 gradient 계산\n",
    "    optimizer.step()                # 가중치 업데이트 : 계산된 gradient 를 사용해 파라미터 업데이트\n",
    "\n",
    "    if epoch % 1000 == 0 : \n",
    "         print(f\"Epoch{epoch}: loss={loss.item():.4f}\") # 소수점 4자리의 지수표현식으로 표현\n",
    "\n",
    "# 결과 확인\n",
    "with torch.no_grad():               # 평가 단계에서는 gradient 계산 하지않음 (메모리 절약, 속도 향상)\n",
    "     prediction = model(X).round()  # 모델 출력이 0~1 확률 값. round()는 반올림 (0.5기준으로 0/1반환)\n",
    "     print(\"최종 예측:\",prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6bda37",
   "metadata": {},
   "source": [
    "XOR 정도 되는 비선형 문제를 해결할려면 은닉층 노드 수가 최소 2개 이상이어야 한다.\n",
    "\n",
    "relu 활성화 함수 대신 tanh 함수 사용: 초기 학습 안정성에 도움이 된다.\n",
    "\n",
    "출력층 Sigmoid 활성화 함수 + BCE 손실함수 : 이진분류에 매우 적합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b648f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
