{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487c0cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 정규화\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()     # nn.Module 초기화(부모 클래스 생성자)\n",
    "        self.fc1 = nn.Linear(784, 128)        # 입력 784 -> 은닉층1(128) 선형 변환\n",
    "        self.bn1 = nn.BatchNorm1d(128)        # 은닉층 1 (128차원) 배치 정규화\n",
    "        # ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)         # 은닉층 1(128) -> (64차원) 배치 정규화\n",
    "        self.bn2 = nn.BatchNorm1d(64)         # 은닉층 2 출력 (64차원) 배치 정규화\n",
    "        # ReLU()\n",
    "        self.fc3 = nn.Linear(64, 10)          # 은닉층 2(64) -> 출력층 (10 클래스) 선형 변환\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x))) # ReLU1(()\n",
    "        x = torch.relu(self.bn2(self.fc2(x))) # ReLU2(()\n",
    "        x = self.fc3(x)\n",
    "        return x                              # 최종 logit 반환 (보통 Softmax를  출력함수로 사용한다.)\n",
    "\n",
    "model = NeuralNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9144a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 드롭아웃\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)         # 은닉층1 (128 노드)에 Dropout 적용 (50% 뉴런 비활성화)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)         # 은닉층2 (64 노드)에 Dropout 적용 (30% 뉴런 비활성화)\n",
    "        self.fc3 = nn.Linear(64, 10)            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.dropout1(self.fc1(x)))  # fc1 -> dropout -> ReLU\n",
    "        x = torch.relu(self.dropout2(self.fc2(x)))  # fc2 -> dropout -> ReLU\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb1f6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/jy/dl/dl_venv/lib/python3.13/site-packages (from skorch) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/jy/dl/dl_venv/lib/python3.13/site-packages (from skorch) (1.8.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/jy/dl/dl_venv/lib/python3.13/site-packages (from skorch) (1.16.3)\n",
      "Collecting tabulate>=0.7.7 (from skorch)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /Users/jy/dl/dl_venv/lib/python3.13/site-packages (from skorch) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/jy/dl/dl_venv/lib/python3.13/site-packages (from scikit-learn>=0.22.0->skorch) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/jy/dl/dl_venv/lib/python3.13/site-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n",
      "Downloading skorch-1.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate, skorch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [skorch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed skorch-1.3.1 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d072d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier                          # Pytorch 모델을 sklearn 모델 처럼 쓰게 해주는 래퍼 Claasifier\n",
    "from sklearn.model_selection import RandomizedSearchCV          # 랜덤 탐색 기반 하이퍼파라미터 최적화 도구\n",
    "from scipy.stats import uniform                                 # 연속 구간에서 균등분포로 값 샘플링\n",
    "\n",
    "net = NeuralNetClassifier(      # Pytorch 모델을 sklearn 모델 처럼 분류기처럼 래핑\n",
    "    NeuralNet,                  # 사용할 Pytorch 모델 클래스(nn.Module)\n",
    "    max_epochs=10,              # 학습 반복 횟수\n",
    "    lr=0.01                     # 옵티마이저 학습률\n",
    ")    \n",
    "param_dist = { 'lr': uniform(0.0001, 0.1) }  # lr을 (0.0001, 0.1001) 범위에서 랜덤 샘플링\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=net,                       # 튜닝 대상 모델\n",
    "    param_distributions=param_dist,      # 탐색할 하이퍼파라미터 분포\n",
    "    n_iter=5,                            # 랜덤으로 5개의 조합으로 시도\n",
    "    cv=3,                                # 3-fold 교차검증\n",
    "    verbose=1                            # 진행 고르 출력 레벨\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061129a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# AdamW설정\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),         # 학습할 파라미터 (가중치/편향)\n",
    "    lr = 1e-3,                  # 학습률\n",
    "    weight_decay= 1e-4          # 가중치 감쇠 강도 (L2 제 강도)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
